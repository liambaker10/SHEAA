{% extends "base.html" %} {% block title %}About Models{% endblock %} {% block
content%}
<html>
	<div id="main">
		<link
			rel="stylesheet"
			href="{{ url_for('static', filename='css/style.css') }}"
		/>
		<!-- One -->
		<section id="one">
			<div class="inner">
				<header class="major">
					<h1>This is the Bert-Base-Uncased Model</h1>
					<a href="/tryBert" class="button primary">Try the Model</a>
				</header>
				<span class="image main"
					><img src="static/images/artificial-intelligence.webp" alt=""
				/></span>
				<p>Choose a model name for more information about it</p>
				<!-- Dropdown -->
				<!--<div class="dropdown mt-3">
							<button class="btn btn-secondary dropdown-toggle" type="button"
							id="book-dropdown" data-bs-toggle="dropdown">
								Choose a book title
							</button>
						</div> -->
				<div class="dropdown">
					<link
						href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
						rel="stylesheet"
						integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
						crossorigin="anonymous"
					/>
					<button
						class="btn btn-secondary dropdown-toggle"
						type="button"
						data-bs-toggle="dropdown"
						aria-expanded="false"
					>
						--Select Model--
					</button>
					<ul class="dropdown-menu">
						<li>
							<a class="dropdown-item" href="/AboutModels/GPT-2">GPT-2</a>
						</li>
						<li>
							<a class="dropdown-item" href="/AboutModels/GPT-3.5">GPT-3</a>
						</li>
						<li>
							<a class="dropdown-item" href="/AboutModels/Bert-base"
								>Bert-base</a
							>
						</li>
						<li><a class="dropdown-item" href="/AboutModels/Bart">Bart</a></li>
						<li>
							<a class="dropdown-item" href="/AboutModels/dialGPT">DialGPT</a>
						</li>
					</ul>
				</div>
				<link
					rel="stylesheet"
					href="{{ url_for('static', filename='css/style.css') }}"
				/>
			</div>
		</section>
		<!-- Main -->

		<h4>When was Bert-Base Created?</h4>
		<p>March 11, 2020</p>
		<h4>Primary Users</h4>
		<p>AI researchers and practitioners.</p>
		<h4>Uses</h4>
		<p>
			Bert-Base is commonly used for Masked language modeling (MLM) which
			involves taking a sentence, the model randomly masks 15% of the words in
			the input then run the entire masked sentence through the model and has to
			predict the masked words. It is also used for Next sentence prediction
			(NSP) in which the model concatenates two masked sentences as inputs
			during pretraining. Sometimes they correspond to sentences that were next
			to each other in the original text, sometimes not. The model then has to
			predict if the two sentences were following each other or not.
		</p>
		<h4>Training</h4>
		<p>
			The BERT model was pretrained on BookCorpus, a dataset consisting of
			11,038 unpublished books and English Wikipedia (excluding lists, tables
			and headers).
		</p>
		<h4>General Data</h4>
		<p>Number of Parameters: 110M</p>
		<p>Number of Layers: 12</p>
		<p>Number of Heads: 12</p>
		<p>Model Size: 730 KB</p>
	</div>
</html>
{% endblock %}
